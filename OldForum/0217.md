**Name:** root
**Date:** 05/20/04-06:00:52 AM Z

  - **Next message:** [David MENTRE: "On formal correctness and
    readability (was: Re: [Maxima] Re: [Axiom-developer]
    Re: FeynCalc -\> MAXIMA)"](0218.html)
  - **Previous message:** [root: "Re: [Maxima] Re:
    [Axiom-developer] Re: FeynCalc -\> MAXIMA"](0216.html)
  - **In reply to:** [C Y: "Re: [Axiom-developer] FeynCalc -\>
    MAXIMA"](0215.html)
  - **Next in thread:** [Camm Maguire: "Re: FeynCalc -\>
    MAXIMA"](0222.html)

-----

*\> \> The pamphlet is intended to reference other pamphlets thru the*  
*\> \> bibliogrphy. Pamphlets are intended to stay very close to the*  
*\> \> what scientists know and extending it carefully. The next step*  
*\> \> is to introduce semantic latex tags like \\concept{ }*  
*\> So, it won't be possible to load the pamphlet from the paper into
Axiom*  
*\> and have the algorithm(s) defined there available?*  

ummm, pamphlets contain the algorithms. If they reference other  
algorithms it would be thru the bibliograpy. I have a bibtex file  
for the current Axiom pamphlets but have not yet incorporated it  
into the released build.  

The comment about "staying close to what scientists know" is a  
reference to the fact that most papers today use TeX. The noweb  
technology by Norman Ramsey make some very simple extensions to  
the TeX markup to support literate programs. So a pamphlet without  
code is essentially a TeX document. Adding code requires learning  
two new markup tags and two commands and now you can extract the  
code (the notangle command) and extract the paper (the noweave
command).  

The comment about \\concept{} is a reference to the fact that TeX  
is a syntactic markup. I want to extend TeX with semantic markup  
tags. These would not affect the print format of a paper. However  
they would tag "concepts" that would be pushed into a semantic  
network (ref: KROPS, my pre-axiom area of research). This would  
allow us to search papers for ideas rather than strings.  

*\> \> erm,... I retype the papers from pdf format to TeX format and
then*  
*\> \> include the code (making it a pamphlet). Almost no-one posts
TeX*  
*\> \> so there appears to be no choice. Fateman has been looking at*  
*\> \> recognizers for file formats but a push to collect and store the
TeX*  
*\> \> files would save a tremendous amount of time. In the last year
I've*  
*\> \> retyped approx 500 pages of pdf to TeX.*  

*\> Ouch. What I ment though was when you said there were 1100 domains
in*  
*\> Axiom with no theoretical documentation - is that what the paper*  
*\> conversion is addressing?*  

Yes. I have permission to use several phd thesis papers and several  
research papers but some of them were either professionally typeset  
or done in other markup languages (such as IBM script) so there is no  
TeX available. I'm hand-typing them back into TeX and combining them  
with the domains they document. See dhmatrix.spad.pamphlet which is  
from Richard Paul's PhD thesis in robotics and documents  
Denavit-Hartenberg Matrices, a special kind of homogeneous  
transformation matrix implemented in Axiom. I really wish authors  
would adopt the open source model and publish the raw TeX documents.  

Tim  

-----

  - **Next message:** [David MENTRE: "On formal correctness and
    readability (was: Re: [Maxima] Re: [Axiom-developer]
    Re: FeynCalc -\> MAXIMA)"](0218.html)
  - **Previous message:** [root: "Re: [Maxima] Re:
    [Axiom-developer] Re: FeynCalc -\> MAXIMA"](0216.html)
  - **In reply to:** [C Y: "Re: [Axiom-developer] FeynCalc -\>
    MAXIMA"](0215.html)
  - **Next in thread:** [Camm Maguire: "Re: FeynCalc -\>
    MAXIMA"](0222.html)

-----

